{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opion():\n",
    "    \n",
    "    def __init__(self):\n",
    "            \n",
    "        self.dataroot= r'I:\\irregular holes\\paris_eval_gt' #image dataroot\n",
    "        self.maskroot= r'I:\\irregular holes\\testing_mask_dataset'#mask dataroot\n",
    "        self.batchSize= 1   # Need to be set to 1\n",
    "        self.fineSize=256 # image size\n",
    "        self.input_nc=3  # input channel size for first stage\n",
    "        self.input_nc_g=6 # input channel size for second stage\n",
    "        self.output_nc=3# output channel size\n",
    "        self.ngf=64 # inner channel\n",
    "        self.ndf=64# inner channel\n",
    "        self.which_model_netD='basic' # patch discriminator\n",
    "        \n",
    "        self.which_model_netF='feature'# feature patch discriminator\n",
    "        self.which_model_netG='unet_csa'# seconde stage network\n",
    "        self.which_model_netP='unet_256'# first stage network\n",
    "        self.triple_weight=1\n",
    "        self.name='CSA_inpainting'\n",
    "        self.n_layers_D='3' # network depth\n",
    "        self.gpu_ids=[0]\n",
    "        self.model='csa_net'\n",
    "        self.checkpoints_dir=r'.\\checkpoints' #\n",
    "        self.norm='instance'\n",
    "        self.fixed_mask=1\n",
    "        self.use_dropout=False\n",
    "        self.init_type='normal'\n",
    "        self.mask_type='center'\n",
    "        self.lambda_A=100\n",
    "        self.threshold=5/16.0\n",
    "        self.stride=1\n",
    "        self.shift_sz=1 # size of feature patch\n",
    "        self.mask_thred=1\n",
    "        self.bottleneck=512\n",
    "        self.gp_lambda=10.0\n",
    "        self.ncritic=5\n",
    "        self.constrain='MSE'\n",
    "        self.strength=1\n",
    "        self.init_gain=0.02\n",
    "        self.cosis=1\n",
    "        self.gan_type='lsgan'\n",
    "        self.gan_weight=0.2\n",
    "        self.overlap=4\n",
    "        self.skip=0\n",
    "        self.display_freq=1000\n",
    "        self.print_freq=50\n",
    "        self.save_latest_freq=5000\n",
    "        self.save_epoch_freq=2\n",
    "        self.continue_train=False\n",
    "        self.epoch_count=1\n",
    "        self.phase='train'\n",
    "        self.which_epoch=''\n",
    "        self.niter=20\n",
    "        self.niter_decay=100\n",
    "        self.beta1=0.5\n",
    "        self.lr=0.0002\n",
    "        self.lr_policy='lambda'\n",
    "        self.lr_decay_iters=50\n",
    "        self.isTrain=True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "csa_net\n",
      "initialize network with normal\n",
      "UnetSkipConnectionBlock(\n",
      "  (model): Sequential(\n",
      "    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Jupyter\\ICCV\\Relativistic GAN B C center\\models\\networks.py:53: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, 0.0, gain)\n",
      "I:\\Jupyter\\ICCV\\Relativistic GAN B C center\\models\\networks.py:63: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias.data, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "---------- Networks initialized -------------\n",
      "UnetGeneratorCSA(\n",
      "  (model): UnetSkipConnectionBlock_3(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): UnetSkipConnectionBlock_3(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "          (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (6): UnetSkipConnectionBlock_3(\n",
      "            (model): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "              (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (6): CSA(\n",
      "                (model): Sequential(\n",
      "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                  (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (5): CSA_model(threshold: 0.3125 ,triple_weight 1)\n",
      "                  (6): InnerCos(skip: True ,strength: 1)\n",
      "                  (7): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (8): UnetSkipConnectionBlock_3(\n",
      "                    (model): Sequential(\n",
      "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (6): UnetSkipConnectionBlock_3(\n",
      "                        (model): Sequential(\n",
      "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                          (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (6): UnetSkipConnectionBlock_3(\n",
      "                            (model): Sequential(\n",
      "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                              (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (6): UnetSkipConnectionBlock_3(\n",
      "                                (model): Sequential(\n",
      "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                                  (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (6): UnetSkipConnectionBlock_3(\n",
      "                                    (model): Sequential(\n",
      "                                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                                      (2): ReLU(inplace=True)\n",
      "                                      (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                    )\n",
      "                                  )\n",
      "                                  (7): ReLU(inplace=True)\n",
      "                                  (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                                  (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (10): ReLU(inplace=True)\n",
      "                                  (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                )\n",
      "                              )\n",
      "                              (7): ReLU(inplace=True)\n",
      "                              (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                              (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (10): ReLU(inplace=True)\n",
      "                              (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                            )\n",
      "                          )\n",
      "                          (7): ReLU(inplace=True)\n",
      "                          (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                          (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (10): ReLU(inplace=True)\n",
      "                          (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                        )\n",
      "                      )\n",
      "                      (7): ReLU(inplace=True)\n",
      "                      (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (10): ReLU(inplace=True)\n",
      "                      (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (9): InnerCos2(skip: True ,strength: 1)\n",
      "                  (10): ReLU(inplace=True)\n",
      "                  (11): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (12): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (13): ReLU(inplace=True)\n",
      "                  (14): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (15): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                )\n",
      "              )\n",
      "              (7): ReLU(inplace=True)\n",
      "              (8): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (9): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (10): ReLU(inplace=True)\n",
      "              (11): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (12): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (7): ReLU(inplace=True)\n",
      "          (8): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (10): ReLU(inplace=True)\n",
      "          (11): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (12): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): ConvTranspose2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 77692291\n",
      "UnetGenerator(\n",
      "  (model): UnetSkipConnectionBlock(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): UnetSkipConnectionBlock(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (3): UnetSkipConnectionBlock(\n",
      "            (model): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (3): UnetSkipConnectionBlock(\n",
      "                (model): Sequential(\n",
      "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (3): UnetSkipConnectionBlock(\n",
      "                    (model): Sequential(\n",
      "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (3): UnetSkipConnectionBlock(\n",
      "                        (model): Sequential(\n",
      "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (3): UnetSkipConnectionBlock(\n",
      "                            (model): Sequential(\n",
      "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (3): UnetSkipConnectionBlock(\n",
      "                                (model): Sequential(\n",
      "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (2): ReLU(inplace=True)\n",
      "                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                )\n",
      "                              )\n",
      "                              (4): ReLU(inplace=True)\n",
      "                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                            )\n",
      "                          )\n",
      "                          (4): ReLU(inplace=True)\n",
      "                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                        )\n",
      "                      )\n",
      "                      (4): ReLU(inplace=True)\n",
      "                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (4): ReLU(inplace=True)\n",
      "                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                )\n",
      "              )\n",
      "              (4): ReLU(inplace=True)\n",
      "              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (4): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 54419459\n",
      "NLayerDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 2766529\n",
      "PFDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 10487296\n",
      "-----------------------------------------------\n",
      "model [CSAModel] was created\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from util.data_load import Data_load\n",
    "from models.models import create_model\n",
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "opt = Opion()\n",
    "transform_mask = transforms.Compose(\n",
    "    [transforms.Resize((opt.fineSize,opt.fineSize)),\n",
    "     transforms.ToTensor(),\n",
    "    ])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.Resize((opt.fineSize,opt.fineSize)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])\n",
    "\n",
    "dataset_train = Data_load(opt.dataroot, opt.maskroot, transform, transform_mask, 'train')\n",
    "iterator_train = (data.DataLoader(dataset_train, batch_size=opt.batchSize,shuffle=True,))\n",
    "print(len(dataset_train))\n",
    "model = create_model(opt)\n",
    "total_steps = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('G_GAN', 11.19520092010498), ('G_L1', 110.14077758789062), ('D', 2.2018284797668457), ('F', 2.3328464031219482)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('G_GAN', 11.469480514526367), ('G_L1', 107.3385009765625), ('D', 3.8187179565429688), ('F', 2.0678272247314453)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "#     image, mask, gt = [x.cuda() for x in next(iterator_train)]\n",
    "    for image, mask, gt in (iterator_train):\n",
    "        image=image.cuda()\n",
    "        mask=mask.cuda()\n",
    "        mask=mask[0][0]\n",
    "        mask=torch.unsqueeze(mask,0)\n",
    "        mask=torch.unsqueeze(mask,1)\n",
    "        mask=mask.byte()\n",
    "\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "        model.set_input(image,mask) # it not only sets the input data with mask, but also sets the latent mask.\n",
    "        model.set_gt_latent()\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if total_steps %opt.display_freq== 0:\n",
    "            real_A,real_B,fake_B=model.get_current_visuals()\n",
    "            #real_A=input, real_B=ground truth fake_b=output\n",
    "            pic = (torch.cat([real_A, real_B,fake_B], dim=0) + 1) / 2.0\n",
    "            torchvision.utils.save_image(pic_1, '%s/Epoch_(%d)_(%dof%d).jpg' % (\n",
    "            save_dir, epoch, total_steps + 1, len(dataset_train)), nrow=2)\n",
    "        if total_steps %1== 0:\n",
    "            errors = model.get_current_errors()\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "            print(errors)\n",
    "\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' %\n",
    "                (epoch, total_steps))\n",
    "        model.save(epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "            (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "    model.update_learning_rate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from collections import namedtuple\n",
    "\n",
    "class Vgg16(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(Vgg16, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg16(pretrained=True).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        for x in range(5):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(5, 10):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(10, 17):\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(17, 23):\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.slice1(X)\n",
    "        h_relu1_2 = h\n",
    "        h = self.slice2(h)\n",
    "        h_relu2_2 = h\n",
    "        h = self.slice3(h)\n",
    "        h_relu3_3 = h\n",
    "        h = self.slice4(h)\n",
    "        h_relu4_3 = h\n",
    "        vgg_outputs = namedtuple(\"VggOutputs\", ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3'])\n",
    "        out = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg=Vgg16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vgg16(\n",
       "  (slice1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (slice2): Sequential(\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (slice3): Sequential(\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (slice4): Sequential(\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
