{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "class Opion():\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "            \r\n",
    "        self.dataroot= r'I:\\irregular holes\\paris_eval_gt' #image dataroot\r\n",
    "        self.s1_dataroot= r'I:\\irregular holes\\paris_eval_gt' #sent1 dataroot\r\n",
    "        self.maskroot= r'I:\\irregular holes\\testing_mask_dataset'#mask dataroot\r\n",
    "        self.batchSize= 1   # Need to be set to 1\r\n",
    "        self.fineSize=512 # image size\r\n",
    "        self.input_nc=16  # input channel size for first stage\r\n",
    "        self.input_nc_g=28 # input channel size for second stage\r\n",
    "        self.output_nc=12# output channel size\r\n",
    "        self.ngf=64 # inner channel\r\n",
    "        self.ndf=64# inner channel\r\n",
    "        self.which_model_netD='basic' # patch discriminator\r\n",
    "        \r\n",
    "        self.which_model_netF='feature'# feature patch discriminator\r\n",
    "        self.which_model_netG='unet_csa'# seconde stage network\r\n",
    "        self.which_model_netP='unet_256'# first stage network\r\n",
    "        self.triple_weight=1\r\n",
    "        self.name='CSA_inpainting'\r\n",
    "        self.n_layers_D='3' # network depth\r\n",
    "        self.gpu_ids=[0]\r\n",
    "        self.model='csa_net'\r\n",
    "        self.checkpoints_dir=r'.\\checkpoints' #\r\n",
    "        self.pretrained_dir = 'pretrained/vgg16_s2_weights.pth'\r\n",
    "        self.norm='instance'\r\n",
    "        self.fixed_mask=1\r\n",
    "        self.use_dropout=False\r\n",
    "        self.init_type='normal'\r\n",
    "        self.mask_type='manual'\r\n",
    "        self.lambda_A=100\r\n",
    "        self.threshold=5/16.0\r\n",
    "        self.stride=1\r\n",
    "        self.shift_sz=1 # size of feature patch\r\n",
    "        self.mask_thred=1\r\n",
    "        self.bottleneck=512\r\n",
    "        self.gp_lambda=10.0\r\n",
    "        self.ncritic=5\r\n",
    "        self.constrain='MSE'\r\n",
    "        self.strength=1\r\n",
    "        self.init_gain=0.02\r\n",
    "        self.cosis=1\r\n",
    "        self.gan_type='lsgan'\r\n",
    "        self.gan_weight=0.2\r\n",
    "        self.overlap=4\r\n",
    "        self.skip=0\r\n",
    "        self.display_freq=1000\r\n",
    "        self.print_freq=50\r\n",
    "        self.save_latest_freq=5000\r\n",
    "        self.save_epoch_freq=2\r\n",
    "        self.continue_train=False\r\n",
    "        self.epoch_count=1\r\n",
    "        self.phase='train'\r\n",
    "        self.which_epoch=''\r\n",
    "        self.niter=20\r\n",
    "        self.niter_decay=100\r\n",
    "        self.beta1=0.5\r\n",
    "        self.lr=0.0002\r\n",
    "        self.lr_policy='lambda'\r\n",
    "        self.lr_decay_iters=50\r\n",
    "        self.isTrain=True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import time\r\n",
    "from util.data_load import Data_load\r\n",
    "from models.models import create_model\r\n",
    "import torch\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import torchvision\r\n",
    "from torch.utils import data\r\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# seed = np.random.randint(0, 151981651)\r\n",
    "# seed = 0\r\n",
    "# torch.manual_seed(seed)\r\n",
    "tensor = torch.rand((12, 512, 512), dtype=torch.float32)*65535\r\n",
    "tensor2 = tensor.clone()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "rand = np.random.choice([0, 1])\r\n",
    "data_cast = transforms.Lambda(lambda x: (torch.clamp(x, 0, 65535)/65535*255).type(torch.uint8))\r\n",
    "t = transforms.Compose([\r\n",
    "    transforms.ToPILImage(),\r\n",
    "    transforms.RandomHorizontalFlip(rand),\r\n",
    "    transforms.ToTensor()\r\n",
    "                        ])\r\n",
    "normalization = [transforms.Normalize(mean=[0.5] * n, std=[0.5] * n) for n in [12, 4]]\r\n",
    "\r\n",
    "tr_tensor = data_cast(tensor)\r\n",
    "tr_tensor2 = data_cast(tensor2)\r\n",
    "tr_tensor = torch.cat(tuple(t(tr_tensor[n, :, :]) for n in range(tr_tensor.size(0))), 0)\r\n",
    "tr_tensor2 = torch.cat(tuple(t(tr_tensor2[n, :, :]) for n in range(tr_tensor2.size(0))), 0)\r\n",
    "\r\n",
    "print((tr_tensor == tr_tensor2).all())\r\n",
    "# tensor == tensor2\r\n",
    "# print(tensor/tensor.max([1, 2], True)*255)\r\n",
    "# data_cast(tr_tensor)\r\n",
    "normalization[0](tr_tensor)[0, ...].max()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(True)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.9922)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "opt = Opion()\r\n",
    "rand = np.random.choice([0, 1])\r\n",
    "\r\n",
    "# TODO: Must find what minimum and maximum values Sentinel 1 images take\r\n",
    "data_cast = [transforms.Lambda(lambda x: (torch.clamp(x, min_, max_)/max_*255).type(torch.uint8)) for min_, max_ in [(0, 65535), (-20, 30)]]\r\n",
    "transform = transforms.Compose([\r\n",
    "    transforms.ToPILImage(),\r\n",
    "    transforms.RandomHorizontalFlip(rand),\r\n",
    "    transforms.ToTensor()\r\n",
    "                        ])\r\n",
    "normalization = [transforms.Normalize(mean=[0.5] * n, std=[0.5] * n) for n in [12, 4]]\r\n",
    "\r\n",
    "dataset_train = Data_load(opt.dataroot, opt.maskroot, opt.s1_dataroot, transform, normalization, data_cast)\r\n",
    "iterator_train = (data.DataLoader(dataset_train, batch_size=opt.batchSize,shuffle=True))\r\n",
    "print(len(dataset_train))\r\n",
    "model = create_model(opt)\r\n",
    "total_steps = 0\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "iter_start_time = time.time()\r\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\r\n",
    "    \r\n",
    "    epoch_start_time = time.time()\r\n",
    "    epoch_iter = 0\r\n",
    "\r\n",
    "#     image, mask, gt = [x.cuda() for x in next(iterator_train)]\r\n",
    "    for image, mask, sent1 in (iterator_train):\r\n",
    "        image=image.cuda()\r\n",
    "        mask=mask.cuda()\r\n",
    "        sent1=sent1.cuda()\r\n",
    "        mask=mask[0][0]\r\n",
    "        mask=torch.unsqueeze(mask,0)\r\n",
    "        mask=torch.unsqueeze(mask,1)\r\n",
    "        mask=mask.byte()\r\n",
    "\r\n",
    "        total_steps += opt.batchSize\r\n",
    "        epoch_iter += opt.batchSize\r\n",
    "        model.set_input(image,mask,sent1) # it not only sets the input data with mask, but also sets the latent mask.\r\n",
    "        model.set_gt_latent()\r\n",
    "        model.optimize_parameters()\r\n",
    "\r\n",
    "        if total_steps %opt.display_freq== 0:\r\n",
    "            real_A,real_B,fake_B=model.get_current_visuals()\r\n",
    "            #real_A=input, real_B=ground truth fake_b=output\r\n",
    "            pic = (torch.cat([real_A, real_B,fake_B], dim=0) + 1) / 2.0\r\n",
    "            torchvision.utils.save_image(pic, '%s/Epoch_(%d)_(%dof%d).jpg' % (\r\n",
    "            save_dir, epoch, total_steps + 1, len(dataset_train)), nrow=2) # Define save_dir\r\n",
    "        if total_steps %1== 0:\r\n",
    "            errors = model.get_current_errors()\r\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\r\n",
    "            print(errors)\r\n",
    "\r\n",
    "    if epoch % opt.save_epoch_freq == 0:\r\n",
    "        print('saving the model at the end of epoch %d, iters %d' %\r\n",
    "                (epoch, total_steps))\r\n",
    "        model.save(epoch)\r\n",
    "\r\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\r\n",
    "            (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\r\n",
    "\r\n",
    "    model.update_learning_rate()\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('CSA-inpainting': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "9c3d4c96c7e151b60691b858213080daab094f7a49ed8c431280a79eb6314e60"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}